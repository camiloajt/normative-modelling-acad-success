{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f2394394-73ce-483d-af9a-19d86af9f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rn\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from utils import COLUMNS_NAME\n",
    "from models import make_encoder_model_vae, make_decoder_model_vae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b5f01-9c61-43a6-8f25-edb82fb56a6a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "35c45808-f58d-4b9e-82cb-9a906ce709dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "datasets_dir = '../../data/datasets/'\n",
    "dataset_name = 'train_dataset.csv'\n",
    "dataset_path = datasets_dir + dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "35afdb0d-4655-4f51-bbd1-786595f44040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDX_STUDENT</th>\n",
       "      <th>COD_PROGRAMA</th>\n",
       "      <th>JORNADA</th>\n",
       "      <th>DURACION</th>\n",
       "      <th>PERIODO_INGRESO</th>\n",
       "      <th>SEXO</th>\n",
       "      <th>ESTADO_CIVIL</th>\n",
       "      <th>ESTRATO</th>\n",
       "      <th>RANGO_EDAD</th>\n",
       "      <th>CONDICION_EXCEPCION</th>\n",
       "      <th>...</th>\n",
       "      <th>RANGO_INGRESOS</th>\n",
       "      <th>RANGO_GASTOS</th>\n",
       "      <th>TIPO_VIVIENDA</th>\n",
       "      <th>PUNTAJE_ICFES</th>\n",
       "      <th>PCN</th>\n",
       "      <th>PLC</th>\n",
       "      <th>PMA</th>\n",
       "      <th>PSC</th>\n",
       "      <th>PIN</th>\n",
       "      <th>GRADUADO_A_TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STUDENT_1367</td>\n",
       "      <td>2711</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STUDENT_1527</td>\n",
       "      <td>2711</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STUDENT_885</td>\n",
       "      <td>2710</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>48</td>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STUDENT_1879</td>\n",
       "      <td>2710</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>248</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STUDENT_1717</td>\n",
       "      <td>2710</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>241</td>\n",
       "      <td>45</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    IDX_STUDENT  COD_PROGRAMA  JORNADA  DURACION  PERIODO_INGRESO  SEXO  \\\n",
       "0  STUDENT_1367          2711        1         6                6     1   \n",
       "1  STUDENT_1527          2711        2         7                3     1   \n",
       "2   STUDENT_885          2710        2         7               12     1   \n",
       "3  STUDENT_1879          2710        1         6                2     1   \n",
       "4  STUDENT_1717          2710        1         6                6     1   \n",
       "\n",
       "   ESTADO_CIVIL  ESTRATO  RANGO_EDAD  CONDICION_EXCEPCION  ...  \\\n",
       "0             1        2           2                    1  ...   \n",
       "1             1        2           4                    1  ...   \n",
       "2             1        1           2                    1  ...   \n",
       "3             1        2           3                    1  ...   \n",
       "4             1        2           4                    1  ...   \n",
       "\n",
       "   RANGO_INGRESOS  RANGO_GASTOS  TIPO_VIVIENDA  PUNTAJE_ICFES  PCN  PLC  PMA  \\\n",
       "0               2             2              1            252   50   49   51   \n",
       "1               1             1              1            250   49   51   51   \n",
       "2               2             2              1            240   46   58   48   \n",
       "3               1             1              2            248   48   55   47   \n",
       "4               4             4              4            241   45   53   51   \n",
       "\n",
       "   PSC  PIN  GRADUADO_A_TIEMPO  \n",
       "0   48   55                  0  \n",
       "1   51   49                  0  \n",
       "2   38   50                  0  \n",
       "3   48   51                  0  \n",
       "4   48   44                  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(dataset_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "588cfb77-e1fe-4e1b-9cc5-0c5d197a691a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1603, 21)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d68de-271f-4971-88fb-59bad3810ec9",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c0497c96-e30f-4d07-82db-3266afee95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0e56311e-ab68-457d-8524-13f72d0caef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "bootstrap_dir = '../../data/bootstrap_ids/' + version +'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5603abf1-baaf-4351-97f9-a5cea08e6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'supervised_vae'\n",
    "models_dir = '../../outputs/' + model_name + '/bootstrap_ids/' + version + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6b4fc3-3495-4bdf-953c-008fc1c5f009",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f1c191eb-e68d-4140-a982-fbaddcaf4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# Set random seed\n",
    "random_seed = 42\n",
    "tf.random.set_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "rn.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e22ebc21-ead4-4164-837d-890e0f68c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "n_bootstrap = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "761aa4b1-4171-460b-9cf2-c075aca50db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 1/10 [00:39<05:58, 39.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 2/10 [01:17<05:10, 38.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [01:56<04:30, 38.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [02:35<03:52, 38.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [03:14<03:14, 38.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [03:50<02:31, 37.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [04:28<01:53, 37.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [05:07<01:16, 38.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [05:44<00:37, 37.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [06:22<00:00, 38.24s/it]\n"
     ]
    }
   ],
   "source": [
    "for i_bootstrap in tqdm(range(n_bootstrap)):\n",
    "    ids_filename = 'cleaned_bootstrap_{:03d}.csv'.format(i_bootstrap)\n",
    "    ids_path = bootstrap_dir + ids_filename\n",
    "    \n",
    "    bootstrap_model_dir = models_dir + '{:03d}'.format(i_bootstrap) + '/'\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # Loading data\n",
    "    dataset_df = pd.read_csv(ids_path)\n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "    x_data = dataset_df[COLUMNS_NAME].values\n",
    "    \n",
    "    scaler = RobustScaler()\n",
    "    x_data_normalized = scaler.fit_transform(x_data)\n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "    age = dataset_df['RANGO_EDAD'].values[:, np.newaxis].astype('float32')\n",
    "    enc_age = OneHotEncoder(sparse_output=False)\n",
    "    one_hot_age = enc_age.fit_transform(age)\n",
    "\n",
    "    gender = dataset_df['SEXO'].values[:, np.newaxis].astype('float32')\n",
    "    enc_gender = OneHotEncoder(sparse_output=False)\n",
    "    one_hot_gender = enc_gender.fit_transform(gender)\n",
    "\n",
    "    y_data = np.concatenate((one_hot_age, one_hot_gender), axis=1).astype('float32')\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # Create the dataset iterator\n",
    "    batch_size = 64\n",
    "    n_samples = x_data.shape[0]\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_data_normalized, y_data))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=n_samples)\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # Create models\n",
    "    n_features = x_data_normalized.shape[1]\n",
    "    n_labels = y_data.shape[1]\n",
    "    h_dim = [100, 100]\n",
    "    z_dim = 20\n",
    "\n",
    "    encoder = make_encoder_model_vae(n_features, h_dim, z_dim)\n",
    "    decoder = make_decoder_model_vae(z_dim + n_labels, n_features, h_dim)\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # Define loss functions\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # Define optimizers\n",
    "    base_lr = 0.0001\n",
    "    max_lr = 0.005\n",
    "\n",
    "    step_size = 2 * np.ceil(n_samples / batch_size)\n",
    "\n",
    "    ae_optimizer = tf.keras.optimizers.Adam(learning_rate=base_lr)\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # Training function\n",
    "    @tf.function\n",
    "    def train_step(batch_x, batch_y):\n",
    "        # -------------------------------------------------------------------------------------------------------------\n",
    "        # Autoencoder\n",
    "        with tf.GradientTape() as ae_tape:\n",
    "            encoder_output = encoder(batch_x, training=True)\n",
    "            decoder_output = decoder(tf.concat([encoder_output, batch_y], axis=1), training=True)\n",
    "\n",
    "            # Autoencoder loss\n",
    "            ae_loss = mse(batch_x, decoder_output)\n",
    "\n",
    "        ae_grads = ae_tape.gradient(ae_loss, encoder.trainable_variables + decoder.trainable_variables)\n",
    "        ae_optimizer.apply_gradients(zip(ae_grads, encoder.trainable_variables + decoder.trainable_variables))\n",
    "\n",
    "\n",
    "        return ae_loss\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # Training loop\n",
    "    global_step = 0\n",
    "    n_epochs = 150\n",
    "    gamma = 0.98\n",
    "    scale_fn = lambda x: gamma ** x\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        epoch_ae_loss_avg = tf.metrics.Mean()\n",
    "\n",
    "        for _, (batch_x, batch_y) in enumerate(train_dataset):\n",
    "            global_step = global_step + 1\n",
    "            cycle = np.floor(1 + global_step / (2 * step_size))\n",
    "            x_lr = np.abs(global_step / step_size - 2 * cycle + 1)\n",
    "            clr = base_lr + (max_lr - base_lr) * max(0, 1 - x_lr) * scale_fn(cycle)\n",
    "            ae_optimizer.lr = clr\n",
    "\n",
    "            ae_loss = train_step(batch_x, batch_y)\n",
    "\n",
    "            epoch_ae_loss_avg(ae_loss)\n",
    "\n",
    "        epoch_time = time.time() - start\n",
    "        \n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # Save models\n",
    "    final_model_dir = bootstrap_model_dir + 'model/'\n",
    "    \n",
    "    encoder.save(final_model_dir + 'encoder.h5')\n",
    "    decoder.save(final_model_dir + 'decoder.h5')\n",
    "\n",
    "    # Save scaler\n",
    "    joblib.dump(scaler, final_model_dir + 'scaler.joblib')\n",
    "\n",
    "    joblib.dump(enc_age, final_model_dir + 'age_encoder.joblib')\n",
    "    joblib.dump(enc_gender, final_model_dir + 'gender_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2051c3fa-9149-442e-93cd-ee2af244b916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
